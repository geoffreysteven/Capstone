{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) \n",
    "n_steps = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "# source: Jason Brownlee - How to Develop LSTM Models for Time Series Forecasting\n",
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Absolute Price LSTM\n",
    "\n",
    "Create a Bidrectional Stacked LSTM for predicting the next day closing price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of pandas train      set: (1777, 22)\n",
      "Shape of pandas validation set: (253, 22)\n",
      "Shape of pandas test       set: (254, 22)\n",
      "\n",
      "Size of train              set: 1777\n",
      "Size of validation         set: 253\n",
      "Size of test               set: 254\n",
      "\n",
      "Shape of numpy train       set: (1777, 22)\n",
      "Shape of numpy validation  set: (253, 22)\n",
      "Shape of numpy test        set: (254, 22)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(\"sp500.pickle\")\n",
    "\n",
    "# choose the correct Y\n",
    "df = df.drop('Target+', axis=1)\n",
    "df = df.drop('Target_', axis=1)\n",
    "df = df.astype('float64')\n",
    "\n",
    "# report initial results\n",
    "print(\"Shape of pandas train      set: {}\".format(df.loc[\"2010-01-01\":\"2017-01-01\"].shape))\n",
    "print(\"Shape of pandas validation set: {}\".format(df.loc[\"2017-01-01\":\"2018-01-01\"].shape))\n",
    "print(\"Shape of pandas test       set: {}\\n\".format(df.loc[\"2018-01-01\":\"2019-01-01\"].shape))\n",
    "\n",
    "# find split coordinates\n",
    "train_size = df.loc[\"2010-01-01\":\"2017-01-01\"].shape[0]\n",
    "validation_size = df.loc[\"2017-01-01\":\"2018-01-01\"].shape[0]\n",
    "test_size = df.loc[\"2018-01-01\":\"2019-01-01\"].shape[0]\n",
    "\n",
    "print(\"Size of train              set: {}\".format(train_size))\n",
    "print(\"Size of validation         set: {}\".format(validation_size))\n",
    "print(\"Size of test               set: {}\\n\".format(test_size))\n",
    "\n",
    "# scale entire dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(df)\n",
    "\n",
    "# define sets\n",
    "train = dataset[0:train_size]\n",
    "validation = dataset[train_size : train_size + validation_size]\n",
    "test  = dataset[train_size + validation_size: ]\n",
    "\n",
    "print(\"Shape of numpy train       set: {}\".format(train.shape))\n",
    "print(\"Shape of numpy validation  set: {}\".format(validation.shape))\n",
    "print(\"Shape of numpy test        set: {}\".format(test.shape))\n",
    "\n",
    "# print(scaler.inverse_transform(test)[0] - \n",
    "# df.loc[\"2018-01-01\":\"2019-01-01\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Steps back: 50\n",
      "Number of Features: 21\n",
      "Train shape       : (1728, 50, 21) (1728,)\n",
      "Validation shape  : (204, 50, 21) (204,)\n",
      "Test shape        : (205, 50, 21) (205,)\n"
     ]
    }
   ],
   "source": [
    "# How many time steps back? - CRITICAL\n",
    "print(\"Number of Steps back:\", n_steps)\n",
    "\n",
    "# convert into X and y\n",
    "X_train, y_train = split_sequences(train, n_steps)\n",
    "X_validation, y_validation = split_sequences(validation, n_steps)\n",
    "X_test,  y_test = split_sequences(test, n_steps)\n",
    "\n",
    "validation_data=(X_validation, y_validation)\n",
    "\n",
    "# define number of features into the model - CRITICAL\n",
    "n_features = X_train.shape[2]\n",
    "print(\"Number of Features:\", n_features)\n",
    "\n",
    "# verify shapes of model inputs\n",
    "print(\"Train shape       :\", X_train.shape, y_train.shape)\n",
    "print(\"Validation shape  :\", X_validation.shape, y_validation.shape)\n",
    "print(\"Test shape        :\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/geoffrey/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/geoffrey/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1728 samples, validate on 204 samples\n",
      "Epoch 1/200\n",
      " - 16s - loss: 0.0040 - acc: 5.7870e-04 - val_loss: 3.4600e-04 - val_acc: 0.0000e+00\n",
      "Epoch 2/200\n",
      " - 15s - loss: 5.0530e-05 - acc: 5.7870e-04 - val_loss: 4.8188e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/200\n",
      " - 15s - loss: 2.2618e-05 - acc: 5.7870e-04 - val_loss: 1.4798e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/200\n",
      " - 15s - loss: 1.4976e-05 - acc: 5.7870e-04 - val_loss: 6.6324e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/200\n",
      " - 15s - loss: 1.7868e-05 - acc: 5.7870e-04 - val_loss: 3.5777e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/200\n",
      " - 15s - loss: 2.7413e-05 - acc: 5.7870e-04 - val_loss: 3.5718e-05 - val_acc: 0.0000e+00\n",
      "Epoch 7/200\n",
      " - 15s - loss: 1.7288e-05 - acc: 5.7870e-04 - val_loss: 1.1900e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/200\n",
      " - 15s - loss: 2.2207e-05 - acc: 5.7870e-04 - val_loss: 3.3589e-05 - val_acc: 0.0000e+00\n",
      "Epoch 9/200\n",
      " - 15s - loss: 1.5492e-05 - acc: 5.7870e-04 - val_loss: 1.9621e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/200\n",
      " - 15s - loss: 2.7139e-05 - acc: 5.7870e-04 - val_loss: 3.0783e-05 - val_acc: 0.0000e+00\n",
      "Epoch 11/200\n",
      " - 15s - loss: 1.5287e-05 - acc: 5.7870e-04 - val_loss: 2.3545e-05 - val_acc: 0.0000e+00\n",
      "Epoch 12/200\n",
      " - 15s - loss: 1.4559e-05 - acc: 5.7870e-04 - val_loss: 1.2657e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/200\n",
      " - 15s - loss: 2.1857e-05 - acc: 5.7870e-04 - val_loss: 1.5191e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/200\n",
      " - 15s - loss: 1.8887e-05 - acc: 5.7870e-04 - val_loss: 1.0955e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/200\n",
      " - 15s - loss: 1.2589e-05 - acc: 5.7870e-04 - val_loss: 4.7909e-05 - val_acc: 0.0000e+00\n",
      "Epoch 16/200\n",
      " - 15s - loss: 2.1107e-05 - acc: 5.7870e-04 - val_loss: 7.5762e-05 - val_acc: 0.0000e+00\n",
      "Epoch 17/200\n",
      " - 15s - loss: 1.5404e-05 - acc: 5.7870e-04 - val_loss: 2.4257e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/200\n",
      " - 15s - loss: 1.2206e-05 - acc: 5.7870e-04 - val_loss: 1.0680e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/200\n",
      " - 15s - loss: 8.7876e-06 - acc: 5.7870e-04 - val_loss: 6.2534e-05 - val_acc: 0.0000e+00\n",
      "Epoch 20/200\n",
      " - 15s - loss: 2.0046e-05 - acc: 5.7870e-04 - val_loss: 1.4984e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/200\n",
      " - 15s - loss: 2.1196e-05 - acc: 5.7870e-04 - val_loss: 3.5066e-05 - val_acc: 0.0000e+00\n",
      "Epoch 22/200\n",
      " - 15s - loss: 8.8125e-06 - acc: 5.7870e-04 - val_loss: 7.8141e-06 - val_acc: 0.0000e+00\n",
      "Epoch 23/200\n",
      " - 15s - loss: 1.1529e-05 - acc: 5.7870e-04 - val_loss: 3.6802e-05 - val_acc: 0.0000e+00\n",
      "Epoch 24/200\n",
      " - 15s - loss: 1.7276e-05 - acc: 5.7870e-04 - val_loss: 5.2834e-05 - val_acc: 0.0000e+00\n",
      "Epoch 25/200\n",
      " - 15s - loss: 9.1828e-06 - acc: 5.7870e-04 - val_loss: 5.8658e-06 - val_acc: 0.0000e+00\n",
      "Epoch 26/200\n",
      " - 15s - loss: 1.1332e-05 - acc: 5.7870e-04 - val_loss: 7.3286e-06 - val_acc: 0.0000e+00\n",
      "Epoch 27/200\n",
      " - 15s - loss: 1.1727e-05 - acc: 5.7870e-04 - val_loss: 1.6615e-05 - val_acc: 0.0000e+00\n",
      "Epoch 28/200\n",
      " - 15s - loss: 1.2581e-05 - acc: 5.7870e-04 - val_loss: 9.6904e-05 - val_acc: 0.0000e+00\n",
      "Epoch 29/200\n",
      " - 15s - loss: 1.3102e-05 - acc: 5.7870e-04 - val_loss: 1.0234e-05 - val_acc: 0.0000e+00\n",
      "Epoch 30/200\n",
      " - 15s - loss: 2.4374e-05 - acc: 5.7870e-04 - val_loss: 3.3877e-05 - val_acc: 0.0000e+00\n",
      "Epoch 31/200\n",
      " - 15s - loss: 1.1319e-05 - acc: 5.7870e-04 - val_loss: 1.7843e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/200\n",
      " - 15s - loss: 9.4162e-06 - acc: 5.7870e-04 - val_loss: 2.1930e-05 - val_acc: 0.0000e+00\n",
      "Epoch 33/200\n",
      " - 15s - loss: 9.3663e-06 - acc: 5.7870e-04 - val_loss: 6.5149e-05 - val_acc: 0.0000e+00\n",
      "Epoch 34/200\n",
      " - 15s - loss: 8.1688e-06 - acc: 5.7870e-04 - val_loss: 1.5083e-05 - val_acc: 0.0000e+00\n",
      "Epoch 35/200\n",
      " - 15s - loss: 1.6135e-05 - acc: 5.7870e-04 - val_loss: 9.8130e-05 - val_acc: 0.0000e+00\n",
      "Epoch 36/200\n",
      " - 15s - loss: 9.8593e-06 - acc: 5.7870e-04 - val_loss: 1.2933e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/200\n",
      " - 15s - loss: 1.7508e-05 - acc: 5.7870e-04 - val_loss: 3.7922e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/200\n",
      " - 15s - loss: 1.4110e-05 - acc: 5.7870e-04 - val_loss: 2.0529e-05 - val_acc: 0.0000e+00\n",
      "Epoch 39/200\n",
      " - 15s - loss: 6.6129e-06 - acc: 5.7870e-04 - val_loss: 5.1470e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/200\n",
      " - 15s - loss: 1.5081e-05 - acc: 5.7870e-04 - val_loss: 4.3071e-05 - val_acc: 0.0000e+00\n",
      "Epoch 41/200\n",
      " - 15s - loss: 1.3775e-05 - acc: 5.7870e-04 - val_loss: 6.9580e-05 - val_acc: 0.0000e+00\n",
      "Epoch 42/200\n",
      " - 15s - loss: 3.0177e-05 - acc: 5.7870e-04 - val_loss: 8.3721e-05 - val_acc: 0.0000e+00\n",
      "Epoch 43/200\n",
      " - 15s - loss: 7.3373e-06 - acc: 5.7870e-04 - val_loss: 2.7054e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/200\n",
      " - 15s - loss: 4.4906e-06 - acc: 5.7870e-04 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 45/200\n",
      " - 15s - loss: 1.5402e-05 - acc: 5.7870e-04 - val_loss: 0.4808 - val_acc: 0.0000e+00\n",
      "Epoch 46/200\n",
      " - 15s - loss: 2.8419e-06 - acc: 5.7870e-04 - val_loss: 0.4516 - val_acc: 0.0000e+00\n",
      "Epoch 47/200\n",
      " - 15s - loss: 4.2091e-06 - acc: 5.7870e-04 - val_loss: 0.9240 - val_acc: 0.0000e+00\n",
      "Epoch 48/200\n",
      " - 15s - loss: 7.3306e-06 - acc: 5.7870e-04 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 49/200\n",
      " - 15s - loss: 3.8109e-06 - acc: 5.7870e-04 - val_loss: 0.0474 - val_acc: 0.0000e+00\n",
      "Epoch 50/200\n",
      " - 15s - loss: 8.3948e-06 - acc: 5.7870e-04 - val_loss: 9.3766e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/200\n",
      " - 15s - loss: 7.8532e-06 - acc: 5.7870e-04 - val_loss: 0.1024 - val_acc: 0.0000e+00\n",
      "Epoch 52/200\n",
      " - 15s - loss: 2.9882e-06 - acc: 5.7870e-04 - val_loss: 0.7066 - val_acc: 0.0000e+00\n",
      "Epoch 53/200\n",
      " - 15s - loss: 1.2165e-05 - acc: 5.7870e-04 - val_loss: 1.2310 - val_acc: 0.0000e+00\n",
      "Epoch 54/200\n",
      " - 15s - loss: 6.0290e-06 - acc: 5.7870e-04 - val_loss: 0.0607 - val_acc: 0.0000e+00\n",
      "Epoch 55/200\n",
      " - 15s - loss: 4.3107e-05 - acc: 5.7870e-04 - val_loss: 9.0343 - val_acc: 0.0000e+00\n",
      "Epoch 56/200\n",
      " - 15s - loss: 6.9167e-06 - acc: 5.7870e-04 - val_loss: 5.7997 - val_acc: 0.0000e+00\n",
      "Epoch 57/200\n",
      " - 15s - loss: 2.3364e-06 - acc: 5.7870e-04 - val_loss: 7.3921 - val_acc: 0.0000e+00\n",
      "Epoch 58/200\n",
      " - 15s - loss: 2.0154e-06 - acc: 5.7870e-04 - val_loss: 3.5805 - val_acc: 0.0000e+00\n",
      "Epoch 59/200\n",
      " - 15s - loss: 3.8514e-06 - acc: 5.7870e-04 - val_loss: 0.3749 - val_acc: 0.0000e+00\n",
      "Epoch 60/200\n",
      " - 15s - loss: 6.1370e-06 - acc: 5.7870e-04 - val_loss: 3.2823e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/200\n",
      " - 15s - loss: 1.7965e-06 - acc: 5.7870e-04 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 62/200\n",
      " - 15s - loss: 9.8164e-06 - acc: 5.7870e-04 - val_loss: 2.9458e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/200\n",
      " - 15s - loss: 5.3534e-06 - acc: 5.7870e-04 - val_loss: 9.7656e-06 - val_acc: 0.0000e+00\n",
      "Epoch 64/200\n",
      " - 15s - loss: 1.6313e-05 - acc: 5.7870e-04 - val_loss: 1.7763e-05 - val_acc: 0.0000e+00\n",
      "Epoch 65/200\n",
      " - 15s - loss: 5.0133e-06 - acc: 5.7870e-04 - val_loss: 0.0429 - val_acc: 0.0000e+00\n",
      "Epoch 66/200\n",
      " - 15s - loss: 1.0160e-05 - acc: 5.7870e-04 - val_loss: 0.1075 - val_acc: 0.0000e+00\n",
      "Epoch 67/200\n",
      " - 15s - loss: 3.2494e-06 - acc: 5.7870e-04 - val_loss: 0.3265 - val_acc: 0.0000e+00\n",
      "Epoch 68/200\n",
      " - 15s - loss: 6.2014e-06 - acc: 5.7870e-04 - val_loss: 0.7738 - val_acc: 0.0000e+00\n",
      "Epoch 69/200\n",
      " - 15s - loss: 1.8559e-05 - acc: 5.7870e-04 - val_loss: 7.9681 - val_acc: 0.0000e+00\n",
      "Epoch 70/200\n",
      " - 15s - loss: 3.6623e-06 - acc: 5.7870e-04 - val_loss: 5.6758 - val_acc: 0.0000e+00\n",
      "Epoch 71/200\n",
      " - 15s - loss: 2.7052e-06 - acc: 5.7870e-04 - val_loss: 3.3449 - val_acc: 0.0000e+00\n",
      "Epoch 72/200\n",
      " - 15s - loss: 1.8690e-06 - acc: 5.7870e-04 - val_loss: 7.4999 - val_acc: 0.0000e+00\n",
      "Epoch 73/200\n",
      " - 15s - loss: 2.4635e-06 - acc: 5.7870e-04 - val_loss: 30.5690 - val_acc: 0.0000e+00\n",
      "Epoch 74/200\n",
      " - 15s - loss: 3.5164e-06 - acc: 5.7870e-04 - val_loss: 122.4833 - val_acc: 0.0000e+00\n",
      "Epoch 75/200\n",
      " - 15s - loss: 2.2169e-06 - acc: 5.7870e-04 - val_loss: 33.7159 - val_acc: 0.0000e+00\n",
      "Epoch 76/200\n",
      " - 15s - loss: 6.7605e-06 - acc: 5.7870e-04 - val_loss: 19.4188 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/200\n",
      " - 15s - loss: 3.3975e-06 - acc: 5.7870e-04 - val_loss: 5.0305 - val_acc: 0.0000e+00\n",
      "Epoch 78/200\n",
      " - 15s - loss: 6.2631e-06 - acc: 5.7870e-04 - val_loss: 1.6684e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/200\n",
      " - 15s - loss: 1.4157e-05 - acc: 5.7870e-04 - val_loss: 1.4754e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/200\n",
      " - 15s - loss: 4.3060e-06 - acc: 5.7870e-04 - val_loss: 1.0998e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/200\n",
      " - 15s - loss: 1.7893e-06 - acc: 5.7870e-04 - val_loss: 2.1156e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/200\n",
      " - 15s - loss: 6.8605e-06 - acc: 5.7870e-04 - val_loss: 5.8300e-05 - val_acc: 0.0000e+00\n",
      "Epoch 83/200\n",
      " - 15s - loss: 4.9467e-06 - acc: 5.7870e-04 - val_loss: 34.3412 - val_acc: 0.0000e+00\n",
      "Epoch 84/200\n",
      " - 15s - loss: 3.4705e-06 - acc: 5.7870e-04 - val_loss: 1.5286e-05 - val_acc: 0.0000e+00\n",
      "Epoch 85/200\n",
      " - 15s - loss: 5.4518e-06 - acc: 5.7870e-04 - val_loss: 1.0435e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/200\n",
      " - 15s - loss: 2.6858e-06 - acc: 5.7870e-04 - val_loss: 5.8111e-06 - val_acc: 0.0000e+00\n",
      "Epoch 87/200\n",
      " - 15s - loss: 3.2924e-06 - acc: 5.7870e-04 - val_loss: 5.1342e-05 - val_acc: 0.0000e+00\n",
      "Epoch 88/200\n",
      " - 15s - loss: 4.8312e-06 - acc: 5.7870e-04 - val_loss: 5.5015e-05 - val_acc: 0.0000e+00\n",
      "Epoch 89/200\n",
      " - 15s - loss: 4.2844e-06 - acc: 5.7870e-04 - val_loss: 4.4921e-05 - val_acc: 0.0000e+00\n",
      "Epoch 90/200\n",
      " - 15s - loss: 9.3697e-06 - acc: 5.7870e-04 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 91/200\n",
      " - 15s - loss: 6.0803e-06 - acc: 5.7870e-04 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 92/200\n",
      " - 15s - loss: 4.1620e-06 - acc: 5.7870e-04 - val_loss: 7.4154e-04 - val_acc: 0.0000e+00\n",
      "Epoch 93/200\n",
      " - 15s - loss: 2.6551e-06 - acc: 5.7870e-04 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 94/200\n",
      " - 15s - loss: 1.6560e-06 - acc: 5.7870e-04 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 95/200\n",
      " - 15s - loss: 6.5012e-06 - acc: 5.7870e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 96/200\n",
      " - 15s - loss: 1.6931e-06 - acc: 5.7870e-04 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 97/200\n",
      " - 15s - loss: 5.2720e-06 - acc: 5.7870e-04 - val_loss: 0.0085 - val_acc: 0.0000e+00\n",
      "Epoch 98/200\n",
      " - 15s - loss: 7.1080e-06 - acc: 5.7870e-04 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 99/200\n",
      " - 15s - loss: 2.5775e-06 - acc: 5.7870e-04 - val_loss: 0.0126 - val_acc: 0.0000e+00\n",
      "Epoch 100/200\n",
      " - 15s - loss: 4.8619e-06 - acc: 5.7870e-04 - val_loss: 1.0490e-05 - val_acc: 0.0000e+00\n",
      "Epoch 101/200\n",
      " - 15s - loss: 7.0066e-06 - acc: 5.7870e-04 - val_loss: 4.7583e-06 - val_acc: 0.0000e+00\n",
      "Epoch 102/200\n",
      " - 15s - loss: 1.4733e-06 - acc: 5.7870e-04 - val_loss: 1.0451e-05 - val_acc: 0.0000e+00\n",
      "Epoch 103/200\n",
      " - 15s - loss: 1.4600e-06 - acc: 5.7870e-04 - val_loss: 9.1199e-06 - val_acc: 0.0000e+00\n",
      "Epoch 104/200\n",
      " - 15s - loss: 2.0633e-06 - acc: 5.7870e-04 - val_loss: 8.6131e-06 - val_acc: 0.0000e+00\n",
      "Epoch 105/200\n",
      " - 15s - loss: 6.7695e-06 - acc: 5.7870e-04 - val_loss: 1.9322e-05 - val_acc: 0.0000e+00\n",
      "Epoch 106/200\n",
      " - 15s - loss: 3.0465e-06 - acc: 5.7870e-04 - val_loss: 1.4657e-05 - val_acc: 0.0000e+00\n",
      "Epoch 107/200\n",
      " - 15s - loss: 2.8225e-06 - acc: 5.7870e-04 - val_loss: 5.3608e-05 - val_acc: 0.0000e+00\n",
      "Epoch 108/200\n",
      " - 15s - loss: 4.9625e-06 - acc: 5.7870e-04 - val_loss: 1.5698e-05 - val_acc: 0.0000e+00\n",
      "Epoch 109/200\n",
      " - 15s - loss: 2.1340e-06 - acc: 5.7870e-04 - val_loss: 8.1123e-06 - val_acc: 0.0000e+00\n",
      "Epoch 110/200\n",
      " - 15s - loss: 2.3571e-06 - acc: 5.7870e-04 - val_loss: 5.6914e-05 - val_acc: 0.0000e+00\n",
      "Epoch 111/200\n",
      " - 15s - loss: 2.3135e-06 - acc: 5.7870e-04 - val_loss: 6.6853e-06 - val_acc: 0.0000e+00\n",
      "Epoch 112/200\n",
      " - 15s - loss: 3.0614e-06 - acc: 5.7870e-04 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 113/200\n",
      " - 15s - loss: 6.3548e-06 - acc: 5.7870e-04 - val_loss: 5.5874e-06 - val_acc: 0.0000e+00\n",
      "Epoch 114/200\n",
      " - 15s - loss: 6.2909e-06 - acc: 5.7870e-04 - val_loss: 4.2940e-06 - val_acc: 0.0000e+00\n",
      "Epoch 115/200\n",
      " - 15s - loss: 2.7112e-06 - acc: 5.7870e-04 - val_loss: 3.4065e-06 - val_acc: 0.0000e+00\n",
      "Epoch 116/200\n",
      " - 15s - loss: 2.6062e-06 - acc: 5.7870e-04 - val_loss: 3.2478e-05 - val_acc: 0.0000e+00\n",
      "Epoch 117/200\n",
      " - 15s - loss: 1.5415e-06 - acc: 5.7870e-04 - val_loss: 2.8694e-05 - val_acc: 0.0000e+00\n",
      "Epoch 118/200\n",
      " - 15s - loss: 1.8841e-06 - acc: 5.7870e-04 - val_loss: 7.4839e-05 - val_acc: 0.0000e+00\n",
      "Epoch 119/200\n",
      " - 15s - loss: 1.2048e-05 - acc: 5.7870e-04 - val_loss: 1.4358e-05 - val_acc: 0.0000e+00\n",
      "Epoch 120/200\n",
      " - 15s - loss: 1.6055e-06 - acc: 5.7870e-04 - val_loss: 3.3271e-05 - val_acc: 0.0000e+00\n",
      "Epoch 121/200\n",
      " - 15s - loss: 1.1208e-06 - acc: 5.7870e-04 - val_loss: 3.3252e-05 - val_acc: 0.0000e+00\n",
      "Epoch 122/200\n",
      " - 15s - loss: 2.1425e-06 - acc: 5.7870e-04 - val_loss: 8.6457e-05 - val_acc: 0.0000e+00\n",
      "Epoch 123/200\n",
      " - 15s - loss: 3.5816e-06 - acc: 5.7870e-04 - val_loss: 3.8155e-05 - val_acc: 0.0000e+00\n",
      "Epoch 124/200\n",
      " - 15s - loss: 1.7162e-06 - acc: 5.7870e-04 - val_loss: 6.7899e-05 - val_acc: 0.0000e+00\n",
      "Epoch 125/200\n",
      " - 15s - loss: 3.8845e-06 - acc: 5.7870e-04 - val_loss: 2.1689e-05 - val_acc: 0.0000e+00\n",
      "Epoch 126/200\n",
      " - 15s - loss: 1.4970e-06 - acc: 5.7870e-04 - val_loss: 2.2193e-05 - val_acc: 0.0000e+00\n",
      "Epoch 127/200\n",
      " - 15s - loss: 3.5908e-06 - acc: 5.7870e-04 - val_loss: 1.1504e-05 - val_acc: 0.0000e+00\n",
      "Epoch 128/200\n",
      " - 15s - loss: 3.5977e-06 - acc: 5.7870e-04 - val_loss: 1.8263e-05 - val_acc: 0.0000e+00\n",
      "Epoch 129/200\n",
      " - 15s - loss: 2.0745e-06 - acc: 5.7870e-04 - val_loss: 4.6518e-05 - val_acc: 0.0000e+00\n",
      "Epoch 130/200\n",
      " - 15s - loss: 1.8069e-06 - acc: 5.7870e-04 - val_loss: 3.2654e-05 - val_acc: 0.0000e+00\n",
      "Epoch 131/200\n",
      " - 15s - loss: 6.8094e-06 - acc: 5.7870e-04 - val_loss: 2.3970e-05 - val_acc: 0.0000e+00\n",
      "Epoch 132/200\n",
      " - 15s - loss: 1.4840e-06 - acc: 5.7870e-04 - val_loss: 3.8454e-06 - val_acc: 0.0000e+00\n",
      "Epoch 133/200\n",
      " - 15s - loss: 4.5089e-06 - acc: 5.7870e-04 - val_loss: 3.4571e-05 - val_acc: 0.0000e+00\n",
      "Epoch 134/200\n",
      " - 15s - loss: 4.7674e-06 - acc: 5.7870e-04 - val_loss: 1.2794e-05 - val_acc: 0.0000e+00\n",
      "Epoch 135/200\n",
      " - 15s - loss: 2.4655e-06 - acc: 5.7870e-04 - val_loss: 1.8639e-05 - val_acc: 0.0000e+00\n",
      "Epoch 136/200\n",
      " - 15s - loss: 1.5168e-06 - acc: 5.7870e-04 - val_loss: 1.0840e-05 - val_acc: 0.0000e+00\n",
      "Epoch 137/200\n",
      " - 15s - loss: 9.3380e-07 - acc: 5.7870e-04 - val_loss: 5.8878e-06 - val_acc: 0.0000e+00\n",
      "Epoch 138/200\n",
      " - 15s - loss: 1.4555e-06 - acc: 5.7870e-04 - val_loss: 1.6833e-05 - val_acc: 0.0000e+00\n",
      "Epoch 139/200\n",
      " - 15s - loss: 2.7737e-06 - acc: 5.7870e-04 - val_loss: 4.0075e-05 - val_acc: 0.0000e+00\n",
      "Epoch 140/200\n",
      " - 15s - loss: 1.9123e-06 - acc: 5.7870e-04 - val_loss: 1.8176e-05 - val_acc: 0.0000e+00\n",
      "Epoch 141/200\n",
      " - 15s - loss: 1.3466e-05 - acc: 5.7870e-04 - val_loss: 3.0042e-05 - val_acc: 0.0000e+00\n",
      "Epoch 142/200\n",
      " - 15s - loss: 1.2205e-06 - acc: 5.7870e-04 - val_loss: 6.2579e-06 - val_acc: 0.0000e+00\n",
      "Epoch 143/200\n",
      " - 15s - loss: 1.1932e-06 - acc: 5.7870e-04 - val_loss: 1.3331e-06 - val_acc: 0.0000e+00\n",
      "Epoch 144/200\n",
      " - 15s - loss: 3.2752e-06 - acc: 5.7870e-04 - val_loss: 1.7907e-05 - val_acc: 0.0000e+00\n",
      "Epoch 145/200\n",
      " - 15s - loss: 3.1652e-06 - acc: 5.7870e-04 - val_loss: 1.2033e-06 - val_acc: 0.0000e+00\n",
      "Epoch 146/200\n",
      " - 15s - loss: 2.2878e-06 - acc: 5.7870e-04 - val_loss: 3.1013e-06 - val_acc: 0.0000e+00\n",
      "Epoch 147/200\n",
      " - 15s - loss: 2.1485e-06 - acc: 5.7870e-04 - val_loss: 3.8156e-06 - val_acc: 0.0000e+00\n",
      "Epoch 148/200\n",
      " - 15s - loss: 1.9035e-06 - acc: 5.7870e-04 - val_loss: 2.7544e-05 - val_acc: 0.0000e+00\n",
      "Epoch 149/200\n",
      " - 15s - loss: 2.4533e-06 - acc: 5.7870e-04 - val_loss: 6.4471e-06 - val_acc: 0.0000e+00\n",
      "Epoch 150/200\n",
      " - 15s - loss: 4.5190e-06 - acc: 5.7870e-04 - val_loss: 7.4155e-06 - val_acc: 0.0000e+00\n",
      "Epoch 151/200\n",
      " - 15s - loss: 1.6162e-06 - acc: 5.7870e-04 - val_loss: 2.5218e-06 - val_acc: 0.0000e+00\n",
      "Epoch 152/200\n",
      " - 15s - loss: 5.6806e-06 - acc: 5.7870e-04 - val_loss: 3.7426e-05 - val_acc: 0.0000e+00\n",
      "Epoch 153/200\n",
      " - 15s - loss: 1.9723e-06 - acc: 5.7870e-04 - val_loss: 9.8837e-07 - val_acc: 0.0000e+00\n",
      "Epoch 154/200\n",
      " - 15s - loss: 1.6426e-06 - acc: 5.7870e-04 - val_loss: 5.6852e-06 - val_acc: 0.0000e+00\n",
      "Epoch 155/200\n",
      " - 15s - loss: 1.1699e-06 - acc: 5.7870e-04 - val_loss: 1.8860e-06 - val_acc: 0.0000e+00\n",
      "Epoch 156/200\n",
      " - 15s - loss: 2.7783e-06 - acc: 5.7870e-04 - val_loss: 3.0999e-06 - val_acc: 0.0000e+00\n",
      "Epoch 157/200\n",
      " - 15s - loss: 8.9753e-07 - acc: 5.7870e-04 - val_loss: 5.5172e-06 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158/200\n",
      " - 15s - loss: 1.1432e-05 - acc: 5.7870e-04 - val_loss: 4.7995e-05 - val_acc: 0.0000e+00\n",
      "Epoch 159/200\n",
      " - 15s - loss: 1.3407e-06 - acc: 5.7870e-04 - val_loss: 2.4043e-06 - val_acc: 0.0000e+00\n",
      "Epoch 160/200\n",
      " - 15s - loss: 1.2640e-06 - acc: 5.7870e-04 - val_loss: 7.7358e-06 - val_acc: 0.0000e+00\n",
      "Epoch 161/200\n",
      " - 15s - loss: 1.1626e-06 - acc: 5.7870e-04 - val_loss: 9.4631e-07 - val_acc: 0.0000e+00\n",
      "Epoch 162/200\n",
      " - 15s - loss: 1.1268e-06 - acc: 5.7870e-04 - val_loss: 3.6319e-06 - val_acc: 0.0000e+00\n",
      "Epoch 163/200\n",
      " - 15s - loss: 3.3019e-06 - acc: 5.7870e-04 - val_loss: 2.6613e-06 - val_acc: 0.0000e+00\n",
      "Epoch 164/200\n",
      " - 15s - loss: 2.5265e-06 - acc: 5.7870e-04 - val_loss: 1.8116e-06 - val_acc: 0.0000e+00\n",
      "Epoch 165/200\n",
      " - 15s - loss: 1.5759e-06 - acc: 5.7870e-04 - val_loss: 3.0653e-06 - val_acc: 0.0000e+00\n",
      "Epoch 166/200\n",
      " - 15s - loss: 2.3562e-06 - acc: 5.7870e-04 - val_loss: 5.9429e-06 - val_acc: 0.0000e+00\n",
      "Epoch 167/200\n",
      " - 15s - loss: 1.4997e-06 - acc: 5.7870e-04 - val_loss: 2.4240e-06 - val_acc: 0.0000e+00\n",
      "Epoch 168/200\n",
      " - 15s - loss: 2.9790e-06 - acc: 5.7870e-04 - val_loss: 6.0318e-06 - val_acc: 0.0000e+00\n",
      "Epoch 169/200\n",
      " - 15s - loss: 2.2309e-06 - acc: 5.7870e-04 - val_loss: 5.2088e-06 - val_acc: 0.0000e+00\n",
      "Epoch 170/200\n",
      " - 15s - loss: 1.7921e-06 - acc: 5.7870e-04 - val_loss: 4.9323e-06 - val_acc: 0.0000e+00\n",
      "Epoch 171/200\n",
      " - 15s - loss: 1.1454e-06 - acc: 5.7870e-04 - val_loss: 1.6295e-06 - val_acc: 0.0000e+00\n",
      "Epoch 172/200\n",
      " - 15s - loss: 5.5357e-06 - acc: 5.7870e-04 - val_loss: 2.8543e-05 - val_acc: 0.0000e+00\n",
      "Epoch 173/200\n",
      " - 15s - loss: 2.8184e-06 - acc: 5.7870e-04 - val_loss: 1.9136e-06 - val_acc: 0.0000e+00\n",
      "Epoch 174/200\n",
      " - 15s - loss: 1.1160e-06 - acc: 5.7870e-04 - val_loss: 1.3903e-06 - val_acc: 0.0000e+00\n",
      "Epoch 175/200\n",
      " - 15s - loss: 1.3376e-06 - acc: 5.7870e-04 - val_loss: 3.2004e-06 - val_acc: 0.0000e+00\n",
      "Epoch 176/200\n",
      " - 15s - loss: 1.0878e-06 - acc: 5.7870e-04 - val_loss: 2.8443e-06 - val_acc: 0.0000e+00\n",
      "Epoch 177/200\n",
      " - 15s - loss: 7.7298e-06 - acc: 5.7870e-04 - val_loss: 4.8496e-06 - val_acc: 0.0000e+00\n",
      "Epoch 178/200\n",
      " - 15s - loss: 2.9113e-06 - acc: 5.7870e-04 - val_loss: 3.0223e-06 - val_acc: 0.0000e+00\n",
      "Epoch 179/200\n",
      " - 15s - loss: 1.1640e-06 - acc: 5.7870e-04 - val_loss: 2.5309e-06 - val_acc: 0.0000e+00\n",
      "Epoch 180/200\n",
      " - 15s - loss: 2.5104e-06 - acc: 5.7870e-04 - val_loss: 2.3442e-06 - val_acc: 0.0000e+00\n",
      "Epoch 181/200\n",
      " - 15s - loss: 1.1023e-06 - acc: 5.7870e-04 - val_loss: 2.0838e-06 - val_acc: 0.0000e+00\n",
      "Epoch 182/200\n",
      " - 15s - loss: 2.8976e-06 - acc: 5.7870e-04 - val_loss: 2.2605e-05 - val_acc: 0.0000e+00\n",
      "Epoch 183/200\n",
      " - 15s - loss: 1.3139e-06 - acc: 5.7870e-04 - val_loss: 3.8840e-06 - val_acc: 0.0000e+00\n",
      "Epoch 184/200\n",
      " - 15s - loss: 1.2447e-06 - acc: 5.7870e-04 - val_loss: 6.6846e-06 - val_acc: 0.0000e+00\n",
      "Epoch 185/200\n",
      " - 15s - loss: 7.2354e-07 - acc: 5.7870e-04 - val_loss: 7.9114e-07 - val_acc: 0.0000e+00\n",
      "Epoch 186/200\n",
      " - 15s - loss: 4.6840e-06 - acc: 5.7870e-04 - val_loss: 5.8328e-05 - val_acc: 0.0000e+00\n",
      "Epoch 187/200\n",
      " - 15s - loss: 5.4599e-06 - acc: 5.7870e-04 - val_loss: 8.2311e-06 - val_acc: 0.0000e+00\n",
      "Epoch 188/200\n",
      " - 15s - loss: 1.5590e-06 - acc: 5.7870e-04 - val_loss: 1.9277e-06 - val_acc: 0.0000e+00\n",
      "Epoch 189/200\n",
      " - 15s - loss: 1.2281e-06 - acc: 5.7870e-04 - val_loss: 1.2958e-05 - val_acc: 0.0000e+00\n",
      "Epoch 190/200\n",
      " - 15s - loss: 8.7437e-07 - acc: 5.7870e-04 - val_loss: 9.1579e-06 - val_acc: 0.0000e+00\n",
      "Epoch 191/200\n",
      " - 15s - loss: 1.1232e-06 - acc: 5.7870e-04 - val_loss: 7.9433e-06 - val_acc: 0.0000e+00\n",
      "Epoch 192/200\n",
      " - 15s - loss: 9.3016e-07 - acc: 5.7870e-04 - val_loss: 6.6709e-06 - val_acc: 0.0000e+00\n",
      "Epoch 193/200\n",
      " - 15s - loss: 1.6274e-06 - acc: 5.7870e-04 - val_loss: 3.5029e-06 - val_acc: 0.0000e+00\n",
      "Epoch 194/200\n",
      " - 15s - loss: 4.0042e-06 - acc: 5.7870e-04 - val_loss: 1.6779e-05 - val_acc: 0.0000e+00\n",
      "Epoch 195/200\n",
      " - 15s - loss: 2.9737e-06 - acc: 5.7870e-04 - val_loss: 9.4303e-07 - val_acc: 0.0000e+00\n",
      "Epoch 196/200\n",
      " - 15s - loss: 1.7149e-06 - acc: 5.7870e-04 - val_loss: 2.2135e-06 - val_acc: 0.0000e+00\n",
      "Epoch 197/200\n",
      " - 15s - loss: 8.4337e-07 - acc: 5.7870e-04 - val_loss: 1.2247e-05 - val_acc: 0.0000e+00\n",
      "Epoch 198/200\n",
      " - 15s - loss: 1.5178e-06 - acc: 5.7870e-04 - val_loss: 1.9270e-06 - val_acc: 0.0000e+00\n",
      "Epoch 199/200\n",
      " - 15s - loss: 1.3918e-06 - acc: 5.7870e-04 - val_loss: 4.8006e-06 - val_acc: 0.0000e+00\n",
      "Epoch 200/200\n",
      " - 15s - loss: 2.1912e-06 - acc: 5.7870e-04 - val_loss: 1.3213e-05 - val_acc: 0.0000e+00\n",
      "CPU times: user 1h 44min 16s, sys: 11min 14s, total: 1h 55min 31s\n",
      "Wall time: 49min 31s\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(200, return_sequences=True, activation='relu'), input_shape=(n_steps, n_features)))\n",
    "# model.add(Bidirectional(LSTM(20, return_sequences=True), input_shape=(n_timesteps, 1)))\n",
    "\n",
    "# model.add(LSTM(200, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "# fit model\n",
    "%time history=model.fit(X_train, y_train, \\\n",
    "                        validation_data=validation_data, \\\n",
    "                        epochs=200, batch_size=10, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yhat shape is (205, 1)\n",
      "pred shape is (205,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2772.4988123755866"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model.predict(X_test)\n",
    "a = np.zeros((205,21))\n",
    "print(\"yhat shape is {}\".format(yhat.shape))\n",
    "pred = np.concatenate((a, yhat),  axis=1)\n",
    "pred = scaler.inverse_transform(pred)\n",
    "pred = pred[:,-1]\n",
    "print(\"pred shape is {}\".format(pred.shape))\n",
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yhat shape is (205,)\n",
      "new_y shape is (205, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2783.02001953125"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"yhat shape is {}\".format(y_test.shape))\n",
    "new_y = y_test.reshape(y_test.shape[0],1)\n",
    "print(\"new_y shape is {}\".format(new_y.shape))\n",
    "y_pred = np.concatenate((a, new_y),  axis=1)\n",
    "y_pred = scaler.inverse_transform(y_pred)\n",
    "y_pred = y_pred[:,-1]\n",
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 330.09 RMSE\n"
     ]
    }
   ],
   "source": [
    "testScore = mean_squared_error(pred, y_pred)\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "# trainPredict = model.predict(X_train)\n",
    "# testPredict = model.predict(X_test)\n",
    "# print(trainPredict.shape)\n",
    "\n",
    "# invert predictions\n",
    "# trainPredict = scaler.inverse_transform(trainPredict)\n",
    "# trainY = scaler.inverse_transform([y_train])\n",
    "# testPredict = scaler.inverse_transform(testPredict)\n",
    "# testY = scaler.inverse_transform([y_test])\n",
    "\n",
    "# calculate root mean squared error\n",
    "# trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "# print('Train Score: %.2f RMSE' % (trainScore))\n",
    "# testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "# print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# loss = [min(x, 1000) for x in loss]\n",
    "# val_loss = [min(x, 1000) for x in val_loss]\n",
    "\n",
    "plt.plot(loss[1:])\n",
    "plt.plot(val_loss[1:])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "# acc = [min(x, 1000) for x in acc]\n",
    "# val_acc = [min(x, 1000) for x in val_acc]\n",
    "\n",
    "plt.plot(y_pred[1:])\n",
    "plt.plot(pred)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "Epoch 149/200\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
